{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (4.27.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johan\\documents\\github\\school work\\practicum\\prototype1-sentiment_analysis_ml\\.venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johan\\Documents\\GitHub\\School Work\\Practicum\\Prototype1-Sentiment_Analysis_ML\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 929/929 [00:00<00:00, 458kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.85MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.41MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 79.1kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 501M/501M [00:25<00:00, 19.8MB/s] \n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "# Preprocess text (username and link placeholders)\n",
    "# def preprocess(text):\n",
    "#     new_text = []\n",
    "#     for t in text.split(\" \"):\n",
    "#         t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "#         t = 'http' if t.startswith('http') else t\n",
    "#         new_text.append(t)\n",
    "#     return \" \".join(new_text)\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"the even went without a hitch and it was verry well planned. Staff was helpful with all my issues.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not satisfied. First, there were not enough seats in the venue and students need to get chairs themselves. Second, Audio is inaudible and there were not enough speakers to cover the whole venue. Lastly, The presentation is not visible from the back and ventilation is not enough.\n",
      "['1) negative 0.8866', '2) neutral 0.1059', '3) positive 0.0075']\n"
     ]
    }
   ],
   "source": [
    "#testing Functions.\n",
    "\n",
    "testTxt1 = \"Not satisfied. First, there were not enough seats in the venue and students need to get chairs themselves. Second, Audio is inaudible and there were not enough speakers to cover the whole venue. Lastly, The presentation is not visible from the back and ventilation is not enough.\"\n",
    "testList1 = [\"the event went without a hitch and it was very well planned. Staff was helpful with all my issues.\", \"the event needed more polish and planning. There where no sitting arrangement, no ventilation, no shade and no support.\"]\n",
    "\n",
    "\n",
    "def stringSentement(text):\n",
    "  resultScore = []\n",
    "  encoded_input = tokenizer(text, return_tensors='pt')\n",
    "  output = model(**encoded_input)\n",
    "  scores = output[0][0].detach().numpy()\n",
    "  scores = softmax(scores)\n",
    "  ranking = np.argsort(scores)\n",
    "  ranking = ranking[::-1]\n",
    "  print(text)\n",
    "  for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    resultScore.append(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "  return resultScore\n",
    "\"\"\" code commented out ill go back and make it more effecient later.. gonna go play some games ITS VICATION TIME!\n",
    "def List2Sentiment(datalist):\n",
    "  ListOfScore = []\n",
    "  for i in datalist:\n",
    "      encoded_input = tokenizer(text, return_tensors='pt')\n",
    "      output = model(**encoded_input)\n",
    "      scores = output[0][0].detach().numpy()\n",
    "      scores = softmax(scores)\n",
    "      ranking = np.argsort(scores)\n",
    "      ranking = ranking[::-1]\n",
    "      print(text)\n",
    "      for i in range(scores.shape[0]):\n",
    "        l = config.id2label[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        resultScore.append(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "  return ListOfScore\n",
    " \"\"\"\n",
    "\n",
    "results = stringSentement(testTxt1)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
